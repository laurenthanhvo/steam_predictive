{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7eab823",
   "metadata": {},
   "source": [
    "# Steam AU Reviews & Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f879a",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8cbf6",
   "metadata": {},
   "source": [
    "### Predictive task\n",
    "***Given a user's past sequence of games, what is the next game they buy?***\n",
    "\n",
    "The **input** features for our model include:\n",
    "* Hours played\n",
    "* Number of sessions\n",
    "* Game genre\n",
    "* Review text\n",
    "* Basic user history\n",
    "\n",
    "Note: Review text refers to processed user reviews through TF-IDF vectorization and analyzing sentiment scores. Basic user history refers to a user's past recommendation rate and what games already exist in their Steam library. \n",
    "\n",
    "The **output** of our model is a binary label (1 - recommend, 0 - not recommend) indicating whether the user recommends the game or not. This task is appropriate for supervised learning and aligns directly with models covered in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e8ad9",
   "metadata": {},
   "source": [
    "### Plans: Baselines and Evaluation\n",
    "\n",
    "We plan to use the following baseline models:\n",
    "* Random baseline\n",
    "* Logistic regression\n",
    "* Naive Bayes\n",
    "\n",
    "We plan to evaluate these models by comparing these metrics:\n",
    "* Accuracy\n",
    "* F1 score\n",
    "* Precision/recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177fbf19",
   "metadata": {},
   "source": [
    "## Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "import gzip\n",
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "# Essentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Preprocessing & Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipelines & Feature Combos\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d01d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('data')\n",
    "\n",
    "def load_python_dicts_gz(path: Path, max_rows=None, verbose=True) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(ast.literal_eval(line))\n",
    "            if max_rows is not None and len(rows) >= max_rows:\n",
    "                break\n",
    "            if verbose and i % 100_000 == 0:\n",
    "                print(f\"Read {i} lines from {path.name}...\")\n",
    "\n",
    "    df = pd.json_normalize(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user reviews data\n",
    "reviews_path = DATA_DIR / 'australian_user_reviews.json.gz'\n",
    "reviews = load_python_dicts_gz(reviews_path, max_rows=100_000)\n",
    "\n",
    "print('reviews shape:', reviews.shape)\n",
    "print('reviews columns:')\n",
    "print(list(reviews.columns))\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user items data\n",
    "items_path = DATA_DIR / 'australian_users_items.json.gz'\n",
    "items = load_python_dicts_gz(items_path, max_rows=100)\n",
    "\n",
    "print('items shape:', items.shape)\n",
    "print('items columns:')\n",
    "print(list(items.columns))\n",
    "\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22759a",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb26a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae02e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "309b188e",
   "metadata": {},
   "source": [
    "### Explaratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57fe8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b62674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c3cfdd",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9929e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b666c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "360a2ff2",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c4ffe0",
   "metadata": {},
   "source": [
    "### Baseline models\n",
    "\n",
    "**1) Random baseline**\n",
    "\n",
    "Our first model is the random baseline, which is used to randomly predict either 0 or 1 based on class distribution. In the context of our dataset, it would be whether the user buys a game or not. As it is unpredictable, it is harder to beat than a majority-class baseline where there is an imbalance between buying and not buying a game, but it also ensures that our models will outperform randomness. This model also shows the value of actual machine learning models more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_baseline():\n",
    "    baseline = DummyClassifier(strategy=\"stratified\")\n",
    "    baseline.fit(X_train, y_train)\n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd971646",
   "metadata": {},
   "source": [
    "**2) Logistic regression**\n",
    "\n",
    "Why we included Logistic Regression\n",
    "\n",
    "- Strong and widely used baseline in machine learning.\n",
    "\n",
    "- Works extremely well with high-dimensional sparse features like TF-IDF.\n",
    "\n",
    "- Simple, interpretable, and fast to train.\n",
    "\n",
    "\n",
    "What it does\n",
    "\n",
    "- Learns a weighted linear boundary between recommend / not-recommend.\n",
    "\n",
    "- Weights correspond directly to influential words.\n",
    "\n",
    "- Captures direction and strength of sentiment based on the TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logistic_regression():\n",
    "    model = make_pipeline(\n",
    "        features,\n",
    "        LogisticRegression(max_iter=2000)\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c099aac",
   "metadata": {},
   "source": [
    "**3) Naive Bayes**\n",
    "\n",
    "Why we included Naive Bayes\n",
    "\n",
    "- Classic baseline for text classification tasks.\n",
    "\n",
    "- Very fast to train and evaluate.\n",
    "\n",
    "- Performs surprisingly well on short reviews and simple sentiment.\n",
    "\n",
    "- Helps us check whether TF-IDF alone can produce strong performance.\n",
    "\n",
    "What it does\n",
    "\n",
    "- Uses word frequencies under a conditional independence assumption.\n",
    "\n",
    "- Learns how often words appear in positive vs. negative reviews.\n",
    "\n",
    "- Provides a lightweight benchmark to compare against more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_naive_bayes():\n",
    "    text_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "    nb_model = make_pipeline(\n",
    "        text_vectorizer,\n",
    "        MultinomialNB()\n",
    "    )\n",
    "    nb_model.fit(X_train[\"review\"], y_train)\n",
    "    return nb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff026c",
   "metadata": {},
   "source": [
    "### Final model\n",
    "\n",
    "**Large TF-IDF + Linear SVC**\n",
    "\n",
    "Why LinearSVC?\n",
    "\n",
    "We choose a Linear Support Vector Classifier (LinearSVC) as our final model because:\n",
    "\n",
    "- It performs extremely well on high-dimensional sparse text data\n",
    "\n",
    "- It is more robust than Naive Bayes when features correlate\n",
    "\n",
    "- It scales better than kernel SVM for large datasets\n",
    "\n",
    "- It is fast to train on tens of thousands of TF-IDF features\n",
    "\n",
    "- It handles class imbalance well when paired with strong features\n",
    "\n",
    "Why combine multiple TF-IDF representations?\n",
    "\n",
    "- Our FeatureUnion merges different types of text signals:\n",
    "\n",
    "Word-level TF-IDF (1–2 grams)\n",
    "\n",
    "- captures phrases like “very fun”, “not good”\n",
    "\n",
    "Character-level TF-IDF (3–5 grams)\n",
    "\n",
    "- captures subword patterns\n",
    "\n",
    "- helps with misspellings, slang, repeated letters (“goooood”, “amazzing”)\n",
    "\n",
    "- helps stylized writing common in game reviews\n",
    "\n",
    "Together, these create a richer and more expressive representation of Steam review text.\n",
    "\n",
    "Why C=1.0?\n",
    "\n",
    "- A balanced default that prevents overfitting\n",
    "\n",
    "- Strong performance without needing heavy tuning\n",
    "\n",
    "Why Pipeline?\n",
    "\n",
    "Using make_pipeline ensures:\n",
    "\n",
    "- preprocessing + model are connected\n",
    "\n",
    "- no manual feature handling needed\n",
    "\n",
    "- one unified model object for training + prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df3330",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14780cde",
   "metadata": {},
   "source": [
    "### Baseline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d6d74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47842656",
   "metadata": {},
   "source": [
    "### Final model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c001a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aae9af4c",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b249797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5e47589",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d9531",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
